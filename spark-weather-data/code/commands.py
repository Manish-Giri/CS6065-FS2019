fp = '/user/girimh/data/weather/2019/999999-96409-2019.op'
inTextData = spark.read.format("csv").option("header", "true").option("delimiter","\t").load(fp)
inTextData.count()
#107
>>> inTextData.show(2, False)
# +------------------------------------------------------------------------------------------------------------------------------------------+
# |STN--- WBAN   YEARMODA    TEMP       DEWP      SLP        STP       VISIB      WDSP     MXSPD   GUST    MAX     MIN   PRCP   SNDP   FRSHTT|
# +------------------------------------------------------------------------------------------------------------------------------------------+
# |999999 96409  20190101    20.7 24  9999.9  0  9999.9  0  9999.9  0  999.9  0  999.9  0  999.9  999.9    25.0     9.7   0.00G 999.9  000000|
# |999999 96409  20190102    10.3 24  9999.9  0  9999.9  0  9999.9  0  999.9  0  999.9  0  999.9  999.9    17.6     6.4   0.00G 999.9  000000|
# +------------------------------------------------------------------------------------------------------------------------------------------+
# only showing top 2 rows

name_list = inTextData.schema.names
print(name_list)
# ['STN--- WBAN   YEARMODA    TEMP       DEWP      SLP        STP       VISIB      WDSP     MXSPD   GUST    MAX     MIN   PRCP   SNDP   FRSHTT']
name_list = str(name_list).strip("['']").split(' ')
names = [i for i in name_list if len(i) > 0]
names
# ['STN---', 'WBAN', 'YEARMODA', 'TEMP', 'DEWP', 'SLP', 'STP', 'VISIB', 'WDSP', 'MXSPD', 'GUST', 'MAX', 'MIN', 'PRCP', 'SNDP', 'FRSHTT']
rdd1 = inTextData.rdd
type(rdd1)
# <class 'pyspark.rdd.RDD'>
rdd1.count()
# 107
rdd1.take(2)
# [Row(STN--- WBAN   YEARMODA    TEMP       DEWP      SLP        STP       VISIB      WDSP     MXSPD   GUST    MAX     MIN   PRCP   SNDP   FRSHTT=u'999999 96409  20190101    20.7 24  9999.9  0  9999.9  0  9999.9  0  999.9  0  999.9  0  999.9  999.9    25.0     9.7   0.00G 999.9  000000'), Row(STN--- WBAN   YEARMODA    TEMP       DEWP      SLP        STP       VISIB      WDSP     MXSPD   GUST    MAX     MIN   PRCP   SNDP   FRSHTT=u'999999 96409  20190102    10.3 24  9999.9  0  9999.9  0  9999.9  0  999.9  0  999.9  0  999.9  999.9    17.6     6.4   0.00G 999.9  000000')]
rdd2 = rdd1.map(lambda x: str(x).split('=')[1])
rdd2.take(4)
# ["u'999999 96409  20190101    20.7 24  9999.9  0  9999.9  0  9999.9  0  999.9  0  999.9  0  999.9  999.9    25.0     9.7   0.00G 999.9  000000')", "u'999999 96409  20190102    10.3 24  9999.9  0  9999.9  0  9999.9  0  999.9  0  999.9  0  999.9  999.9    17.6     6.4   0.00G 999.9  000000')", "u'999999 96409  20190103     9.1 24  9999.9  0  9999.9  0  9999.9  0  999.9  0  999.9  0  999.9  999.9    19.8    -3.6*  0.02G 999.9  000000')", "u'999999 96409  20190104    -8.3 24  9999.9  0  9999.9  0  9999.9  0  999.9  0  999.9  0  999.9  999.9    -2.7   -13.9   0.02G 999.9  000000')"]
rdd3 = rdd2.map(lambda x: ' '.join(x.split()))
rdd3.take(4)
# ["u'999999 96409 20190101 20.7 24 9999.9 0 9999.9 0 9999.9 0 999.9 0 999.9 0 999.9 999.9 25.0 9.7 0.00G 999.9 000000')", "u'999999 96409 20190102 10.3 24 9999.9 0 9999.9 0 9999.9 0 999.9 0 999.9 0 999.9 999.9 17.6 6.4 0.00G 999.9 000000')", "u'999999 96409 20190103 9.1 24 9999.9 0 9999.9 0 9999.9 0 999.9 0 999.9 0 999.9 999.9 19.8 -3.6* 0.02G 999.9 000000')", "u'999999 96409 20190104 -8.3 24 9999.9 0 9999.9 0 9999.9 0 999.9 0 999.9 0 999.9 999.9 -2.7 -13.9 0.02G 999.9 000000')"]
rdd4 = rdd3.map(lambda x: x[2:-2])
rdd4.take(4)
# ['999999 96409 20190101 20.7 24 9999.9 0 9999.9 0 9999.9 0 999.9 0 999.9 0 999.9 999.9 25.0 9.7 0.00G 999.9 000000', '999999 96409 20190102 10.3 24 9999.9 0 9999.9 0 9999.9 0 999.9 0 999.9 0 999.9 999.9 17.6 6.4 0.00G 999.9 000000', '999999 96409 20190103 9.1 24 9999.9 0 9999.9 0 9999.9 0 999.9 0 999.9 0 999.9 999.9 19.8 -3.6* 0.02G 999.9 000000', '999999 96409 20190104 -8.3 24 9999.9 0 9999.9 0 9999.9 0 999.9 0 999.9 0 999.9 999.9 -2.7 -13.9 0.02G 999.9 000000']
rdd4.saveAsTextFile(fp+'temp')

fp
# '/user/girimh/data/weather/2019/999999-96409-2019.op'
fp = fp+'/'
fp
# '/user/girimh/data/weather/2019/999999-96409-2019.op/'

rdd4.take(4)
# ['999999 96409 20190101 20.7 24 9999.9 0 9999.9 0 9999.9 0 999.9 0 999.9 0 999.9 999.9 25.0 9.7 0.00G 999.9 000000', '999999 96409 20190102 10.3 24 9999.9 0 9999.9 0 9999.9 0 999.9 0 999.9 0 999.9 999.9 17.6 6.4 0.00G 999.9 000000', '999999 96409 20190103 9.1 24 9999.9 0 9999.9 0 9999.9 0 999.9 0 999.9 0 999.9 999.9 19.8 -3.6* 0.02G 999.9 000000', '999999 96409 20190104 -8.3 24 9999.9 0 9999.9 0 9999.9 0 999.9 0 999.9 0 999.9 999.9 -2.7 -13.9 0.02G 999.9 000000']



rdd4.saveAsTextFile('/user/girimh/data/weather/2019/test_data/temp')
inf = 'user/girimh/data/weather/2019/test_data/temp/part-00000'
newInData = spark.read.csv(inf,header=False,sep=' ')
# Traceback (most recent call last):
#   File "<stdin>", line 1, in <module>
#   File "/usr/hdp/current/spark2-client/python/pyspark/sql/readwriter.py", line 441, in csv
#     return self._df(self._jreader.csv(self._spark._sc._jvm.PythonUtils.toSeq(path)))
#   File "/usr/hdp/current/spark2-client/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1257, in __call__
#   File "/usr/hdp/current/spark2-client/python/pyspark/sql/utils.py", line 69, in deco
#     raise AnalysisException(s.split(': ', 1)[1], stackTrace)
# pyspark.sql.utils.AnalysisException: u'Path does not exist: hdfs://hdfs-0-0.eecscluster:8020/user/girimh/user/girimh/data/weather/2019/test_data/temp/part-00000;'
inf = 'user/girimh/data/weather/2019/test_data/temp/'
newInData = spark.read.csv(inf,header=False,sep=' ')
# Traceback (most recent call last):
#   File "<stdin>", line 1, in <module>
#   File "/usr/hdp/current/spark2-client/python/pyspark/sql/readwriter.py", line 441, in csv
#     return self._df(self._jreader.csv(self._spark._sc._jvm.PythonUtils.toSeq(path)))
#   File "/usr/hdp/current/spark2-client/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1257, in __call__
#   File "/usr/hdp/current/spark2-client/python/pyspark/sql/utils.py", line 69, in deco
#     raise AnalysisException(s.split(': ', 1)[1], stackTrace)
# pyspark.sql.utils.AnalysisException: u'Path does not exist: hdfs://hdfs-0-0.eecscluster:8020/user/girimh/user/girimh/data/weather/2019/test_data/temp;'

inf = 'data/weather/2019/test_data/temp/part-00000'

# is a data frame
newInData = spark.read.csv(inf,header=False,sep=' ')
newInData.show(10)
# +------+-----+--------+-----+---+------+---+------+---+------+----+-----+----+-----+----+-----+-----+-----+------+-----+-----+------+
# |   _c0|  _c1|     _c2|  _c3|_c4|   _c5|_c6|   _c7|_c8|   _c9|_c10| _c11|_c12| _c13|_c14| _c15| _c16| _c17|  _c18| _c19| _c20|  _c21|
# +------+-----+--------+-----+---+------+---+------+---+------+----+-----+----+-----+----+-----+-----+-----+------+-----+-----+------+
# |999999|96409|20190101| 20.7| 24|9999.9|  0|9999.9|  0|9999.9|   0|999.9|   0|999.9|   0|999.9|999.9| 25.0|   9.7|0.00G|999.9|000000|
# |999999|96409|20190102| 10.3| 24|9999.9|  0|9999.9|  0|9999.9|   0|999.9|   0|999.9|   0|999.9|999.9| 17.6|   6.4|0.00G|999.9|000000|
# |999999|96409|20190103|  9.1| 24|9999.9|  0|9999.9|  0|9999.9|   0|999.9|   0|999.9|   0|999.9|999.9| 19.8| -3.6*|0.02G|999.9|000000|
# |999999|96409|20190104| -8.3| 24|9999.9|  0|9999.9|  0|9999.9|   0|999.9|   0|999.9|   0|999.9|999.9| -2.7| -13.9|0.02G|999.9|000000|
# |999999|96409|20190105| -7.5| 24|9999.9|  0|9999.9|  0|9999.9|   0|999.9|   0|999.9|   0|999.9|999.9| -2.7|-20.2*|0.00G|999.9|000000|
# |999999|96409|20190106|-18.9| 24|9999.9|  0|9999.9|  0|9999.9|   0|999.9|   0|999.9|   0|999.9|999.9|-13.0| -23.8|0.00G|999.9|000000|
# |999999|96409|20190107|-17.4| 24|9999.9|  0|9999.9|  0|9999.9|   0|999.9|   0|999.9|   0|999.9|999.9|-13.5| -23.1|0.00G|999.9|000000|
# |999999|96409|20190108|-20.1| 24|9999.9|  0|9999.9|  0|9999.9|   0|999.9|   0|999.9|   0|999.9|999.9|-14.1| -25.6|0.02G|999.9|000000|
# |999999|96409|20190109|-25.5| 24|9999.9|  0|9999.9|  0|9999.9|   0|999.9|   0|999.9|   0|999.9|999.9|-20.6| -33.0|0.01G|999.9|000000|
# |999999|96409|20190110|-32.9| 24|9999.9|  0|9999.9|  0|9999.9|   0|999.9|   0|999.9|   0|999.9|999.9|-28.3| -37.1|0.00G|999.9|000000|
# +------+-----+--------+-----+---+------+---+------+---+------+----+-----+----+-----+----+-----+-----+-----+------+-----+-----+------+

# drop garabge columns
cleanData = newInData.drop('_c4','_c6','_c8','_c10','_c12','_c14')

type(cleanData)
#<class 'pyspark.sql.dataframe.DataFrame'>
type(newInData)
#<class 'pyspark.sql.dataframe.DataFrame'>

cleanData.show(5)
# +------+-----+--------+----+------+------+------+-----+-----+-----+-----+----+------+-----+-----+------+
# |   _c0|  _c1|     _c2| _c3|   _c5|   _c7|   _c9| _c11| _c13| _c15| _c16|_c17|  _c18| _c19| _c20|  _c21|
# +------+-----+--------+----+------+------+------+-----+-----+-----+-----+----+------+-----+-----+------+
# |999999|96409|20190101|20.7|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|25.0|   9.7|0.00G|999.9|000000|
# |999999|96409|20190102|10.3|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|17.6|   6.4|0.00G|999.9|000000|
# |999999|96409|20190103| 9.1|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|19.8| -3.6*|0.02G|999.9|000000|
# |999999|96409|20190104|-8.3|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|-2.7| -13.9|0.02G|999.9|000000|
# |999999|96409|20190105|-7.5|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|-2.7|-20.2*|0.00G|999.9|000000|
# +------+-----+--------+----+------+------+------+-----+-----+-----+-----+----+------+-----+-----+------+
# only showing top 5 rows

print(names)
#['STN---', 'WBAN', 'YEARMODA', 'TEMP', 'DEWP', 'SLP', 'STP', 'VISIB', 'WDSP', 'MXSPD', 'GUST', 'MAX', 'MIN', 'PRCP', 'SNDP', 'FRSHTT']

cleanData = cleanData.withColumnRenamed('_c0','STN').withColumnRenamed('_c1','WBAN').withColumnRenamed('_c2','YEARMODA')\
                    .withColumnRenamed('_c3','TEMP').withColumnRenamed('_c5','DEWP')\
                    .withColumnRenamed('_c7','SLP').withColumnRenamed('_c9','STP')\
                    .withColumnRenamed('_c11','VISIB').withColumnRenamed('_c13','WDSP')\
                    .withColumnRenamed('_c15','MXSPD').withColumnRenamed('_c16','GUST')\
                    .withColumnRenamed('_c17','MAX').withColumnRenamed('_c18','MIN')\
                    .withColumnRenamed('_c19','PRCP').withColumnRenamed('_c20','SNDP')\
                    .withColumnRenamed('_c21','FRSHTT')

cleanData.printSchema()

# root
#  |-- STN: string (nullable = true)
#  |-- WBAN: string (nullable = true)
#  |-- YEARMODA: string (nullable = true)
#  |-- TEMP: string (nullable = true)
#  |-- DEWP: string (nullable = true)
#  |-- SLP: string (nullable = true)
#  |-- STP: string (nullable = true)
#  |-- VISIB: string (nullable = true)
#  |-- WDSP: string (nullable = true)
#  |-- MXSPD: string (nullable = true)
#  |-- GUST: string (nullable = true)
#  |-- MAX: string (nullable = true)
#  |-- MIN: string (nullable = true)
#  |-- PRCP: string (nullable = true)
#  |-- SNDP: string (nullable = true)
#  |-- FRSHTT: string (nullable = true)

cleanData.count()

cleanData.show(2, False)
# +------+-----+--------+----+------+------+------+-----+-----+-----+-----+----+---+-----+-----+------+
# |STN   |WBAN |YEARMODA|TEMP|DEWP  |SLP   |STP   |VISIB|WDSP |MXSPD|GUST |MAX |MIN|PRCP |SNDP |FRSHTT|
# +------+-----+--------+----+------+------+------+-----+-----+-----+-----+----+---+-----+-----+------+
# |999999|96409|20190101|20.7|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|25.0|9.7|0.00G|999.9|000000|
# |999999|96409|20190102|10.3|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|17.6|6.4|0.00G|999.9|000000|
# +------+-----+--------+----+------+------+------+-----+-----+-----+-----+----+---+-----+-----+------+
# only showing top 2 rows


cleanData.where('TEMP>24').show(2, False)
# +------+-----+--------+----+------+------+------+-----+-----+-----+-----+----+-----+-----+-----+------+
# |STN   |WBAN |YEARMODA|TEMP|DEWP  |SLP   |STP   |VISIB|WDSP |MXSPD|GUST |MAX |MIN  |PRCP |SNDP |FRSHTT|
# +------+-----+--------+----+------+------+------+-----+-----+-----+-----+----+-----+-----+-----+------+
# |999999|96409|20190128|27.8|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|31.8|23.0*|0.00G|999.9|000000|
# |999999|96409|20190208|31.0|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|34.9|28.2 |0.01G|999.9|000000|
# +------+-----+--------+----+------+------+------+-----+-----+-----+-----+----+-----+-----+-----+------+
# only showing top 2 rows

cleanData.select("WBAN").show()
# +-----+
# | WBAN|
# +-----+
# |96409|
# |96409|
# |96409|
# |96409|
# |96409|
# |96409|
# |96409|
# |96409|
# |96409|
# |96409|
# |96409|
# |96409|
# |96409|
# |96409|
# |96409|
# |96409|
# |96409|
# |96409|
# |96409|
# |96409|
# +-----+
# only showing top 20 rows

cleanData.createOrReplaceTempView("weather_2019")
sqlDF = spark.sql("SELECT * FROM weather_2019")
#Hive Session ID = 131572bd-230c-433e-8f0b-45e2e927c661

sqlDF.show()
# +------+-----+--------+-----+------+------+------+-----+-----+-----+-----+------+------+-----+-----+------+
# |   STN| WBAN|YEARMODA| TEMP|  DEWP|   SLP|   STP|VISIB| WDSP|MXSPD| GUST|   MAX|   MIN| PRCP| SNDP|FRSHTT|
# +------+-----+--------+-----+------+------+------+-----+-----+-----+-----+------+------+-----+-----+------+
# |999999|96409|20190101| 20.7|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|  25.0|   9.7|0.00G|999.9|000000|
# |999999|96409|20190102| 10.3|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|  17.6|   6.4|0.00G|999.9|000000|
# |999999|96409|20190103|  9.1|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|  19.8| -3.6*|0.02G|999.9|000000|
# |999999|96409|20190104| -8.3|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|  -2.7| -13.9|0.02G|999.9|000000|
# |999999|96409|20190105| -7.5|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|  -2.7|-20.2*|0.00G|999.9|000000|
# |999999|96409|20190106|-18.9|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9| -13.0| -23.8|0.00G|999.9|000000|
# |999999|96409|20190107|-17.4|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9| -13.5| -23.1|0.00G|999.9|000000|
# |999999|96409|20190108|-20.1|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9| -14.1| -25.6|0.02G|999.9|000000|
# |999999|96409|20190109|-25.5|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9| -20.6| -33.0|0.01G|999.9|000000|
# |999999|96409|20190110|-32.9|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9| -28.3| -37.1|0.00G|999.9|000000|
# |999999|96409|20190111|-35.3|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9| -32.4|-43.8*|0.02G|999.9|000000|
# |999999|96409|20190112|-37.8|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|-27.0*| -43.8|0.00G|999.9|000000|
# |999999|96409|20190113|-10.1|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|   6.8| -32.4|0.00G|999.9|000000|
# |999999|96409|20190114|  9.8|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9| 28.2*|  -4.7|0.05G|999.9|000000|
# |999999|96409|20190115| 16.2|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|  28.2|   9.0|0.00G|999.9|000000|
# |999999|96409|20190116| 14.8|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|  22.3|   7.2|0.00G|999.9|000000|
# |999999|96409|20190117| 10.8|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|  13.1|   7.7|0.00G|999.9|000000|
# |999999|96409|20190118| 10.7|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|  16.5| -1.3*|0.00G|999.9|000000|
# |999999|96409|20190119| -1.5|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|   7.3| -9.4*|0.02G|999.9|000000|
# |999999|96409|20190120|-15.1|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|  -9.0|-23.4*|0.11G|999.9|000000|
# +------+-----+--------+-----+------+------+------+-----+-----+-----+-----+------+------+-----+-----+------+
# only showing top 20 rows

q5DF=spark.sql("SELECT * from weather_2019 where GUST = (SELECT MAX(GUST) from weather_2019)")
q5DF.show()
# +------+-----+--------+-----+------+------+------+-----+-----+-----+-----+------+------+-----+-----+------+
# |   STN| WBAN|YEARMODA| TEMP|  DEWP|   SLP|   STP|VISIB| WDSP|MXSPD| GUST|   MAX|   MIN| PRCP| SNDP|FRSHTT|
# +------+-----+--------+-----+------+------+------+-----+-----+-----+-----+------+------+-----+-----+------+
# |999999|96409|20190101| 20.7|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|  25.0|   9.7|0.00G|999.9|000000|
# |999999|96409|20190102| 10.3|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|  17.6|   6.4|0.00G|999.9|000000|
# |999999|96409|20190103|  9.1|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|  19.8| -3.6*|0.02G|999.9|000000|
# |999999|96409|20190104| -8.3|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|  -2.7| -13.9|0.02G|999.9|000000|
# |999999|96409|20190105| -7.5|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|  -2.7|-20.2*|0.00G|999.9|000000|
# |999999|96409|20190106|-18.9|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9| -13.0| -23.8|0.00G|999.9|000000|
# |999999|96409|20190107|-17.4|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9| -13.5| -23.1|0.00G|999.9|000000|
# |999999|96409|20190108|-20.1|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9| -14.1| -25.6|0.02G|999.9|000000|
# |999999|96409|20190109|-25.5|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9| -20.6| -33.0|0.01G|999.9|000000|
# |999999|96409|20190110|-32.9|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9| -28.3| -37.1|0.00G|999.9|000000|
# |999999|96409|20190111|-35.3|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9| -32.4|-43.8*|0.02G|999.9|000000|
# |999999|96409|20190112|-37.8|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|-27.0*| -43.8|0.00G|999.9|000000|
# |999999|96409|20190113|-10.1|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|   6.8| -32.4|0.00G|999.9|000000|
# |999999|96409|20190114|  9.8|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9| 28.2*|  -4.7|0.05G|999.9|000000|
# |999999|96409|20190115| 16.2|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|  28.2|   9.0|0.00G|999.9|000000|
# |999999|96409|20190116| 14.8|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|  22.3|   7.2|0.00G|999.9|000000|
# |999999|96409|20190117| 10.8|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|  13.1|   7.7|0.00G|999.9|000000|
# |999999|96409|20190118| 10.7|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|  16.5| -1.3*|0.00G|999.9|000000|
# |999999|96409|20190119| -1.5|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|   7.3| -9.4*|0.02G|999.9|000000|
# |999999|96409|20190120|-15.1|9999.9|9999.9|9999.9|999.9|999.9|999.9|999.9|  -9.0|-23.4*|0.11G|999.9|000000|
# +------+-----+--------+-----+------+------+------+-----+-----+-----+-----+------+------+-----+-----+------+
# only showing top 20 rows

spark.sql("SELECT MAX(GUST) from weather_2019").show()
# +---------+
# |max(GUST)|
# +---------+
# |    999.9|
# +---------+


spark.sql("SELECT GUST from weather_2019 WHERE NOT GUST='999.9'").show()
# +----+
# |GUST|
# +----+
# +----+

spark.sql("SELECT COUNT(*) from weather_2019 WHERE STP='9999.9'").show()
# +--------+
# |count(1)|
# +--------+
# |     107|
# +--------+

spark.sql("SELECT MAX(MAX), MIN(MIN) from weather_2019").show()
# +--------+--------+
# |max(MAX)|min(MIN)|
# +--------+--------+
# |  9999.9|    -0.2|
# +--------+--------+


spark.sql("SELECT MAX from weather_2019 where not max='9999.9' and not max LIKE '%*'").show()
# +-----+
# |  MAX|
# +-----+
# | 25.0|
# | 17.6|
# | 19.8|
# | -2.7|
# | -2.7|
# |-13.0|
# |-13.5|
# |-14.1|
# |-20.6|
# |-28.3|
# |-32.4|
# |  6.8|
# | 28.2|
# | 22.3|
# | 13.1|
# | 16.5|
# |  7.3|
# | -9.0|
# |-21.1|
# | 24.4|
# +-----+
# only showing top 20 rows
